---
layout: post
title: "《动手学深度学习（第二版）》学习笔记之 1. 引言"
date: 2025-10-29
tags: [AI, notes]
toc: true
comments: true
author: pianfan
---

## 1.1. 核心概念与定义

**机器学习（machine learning, ML）**：研究计算机系统如何利用经验（通常是数据）提升特定任务性能的技术，结合统计学、数据挖掘和优化思想，常作为实现人工智能的手段。

**深度学习（deep learning, DL）**：机器学习的一个分支，属于多层次表示学习，通过学习多层数据转换实现任务，其核心模型由多层处理单元构成。<!-- more -->

## 1.2. 机器学习关键组件

**数据集**：用于训练和评估模型的数据集合。

**模型**：实现从输入到输出转换的计算机制，深度学习模型包含多层数据转换。

**目标函数（损失函数）**：度量模型优劣的指标，常见如平方误差（回归任务）、错误率（分类任务），部分场景需优化替代目标。

**学习算法**：通过数据集调整模型参数的方法，训练过程通常为：随机初始化参数→用样本调整参数→重复直至性能达标。

**训练集与测试集**：训练集用于拟合参数，测试集用于评估模型泛化能力。

**过拟合**：模型在训练集表现好但无法推广到测试集的现象。

## 1.3. 机器学习问题类型

**监督学习**：利用含标签数据训练，常见任务包括：

  - 多标签分类：预测不互斥的类别

  - 搜索：对项目进行排序

  - 推荐系统：个性化推荐

  - 序列学习：处理输入 / 输出为序列的场景

**无监督学习**：数据无目标标签，任务包括聚类、主成分分析、因果关系与概率图模型、生成对抗网络等。

**强化学习**：研究智能体与环境交互以学习最优策略，涉及观察、动作、奖励等要素，衍生出深度强化学习、马尔可夫决策过程等子问题。

## 1.4. 深度学习起源与发展

**起源**：受神经科学启发，核心原则包括线性与非线性处理单元交替（层）、链式规则（反向传播）调整参数。

**关键进展**：

  - 容量控制（如 dropout）减轻过拟合

  - 注意力机制提升长序列处理能力

  - 多阶段设计支持迭代推理

  - 生成对抗网络革新密度估计

  - 并行分布式训练与计算能力提升（如 GPU 应用）

  - 深度学习框架发展（如 TensorFlow、PyTorch 等）

## 1.5. 深度学习特点

- 端到端训练：联合优化系统整体性能，而非单独调整组件。

- 替代特征工程：自动学习数据表示，取代传统人工特征提取。

- 多级表示学习：通过多层转换实现数据的不同层次表示。

## 1.6. 小结

- 深度学习依赖大量数据与算力突破（如 GPU），推动其近年快速发展。

- 有效的开源框架简化了深度学习的设计与实现，促进技术普及。
